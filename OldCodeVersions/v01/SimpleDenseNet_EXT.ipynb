{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "from typing import Tuple, List\n",
    "import os\n",
    "import sys\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version: 2.3.1\n",
      "Pandas version: 1.1.1\n",
      "NumPy version: 1.18.5\n",
      "OpenCV version: 4.4.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python 3.6.10 :: Anaconda, Inc.\n"
     ]
    }
   ],
   "source": [
    "print(f'Tensorflow version: {tf.__version__}')\n",
    "print(f'Pandas version: {pd.__version__}')\n",
    "print(f'NumPy version: {np.__version__}')\n",
    "print(f'OpenCV version: {cv2.__version__}')\n",
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "We turn this on to prevent tensorflow from throwing a fit about\n",
    "things that take longer than the batch training in the model.fit\n",
    "call (namely, the tensorboard callback can take more time to\n",
    "execute than the batch training iteration itself).\n",
    "\n",
    "NOTE: This can be disabled simply by commenting it out. If you\n",
    "think there is a weird tensorflow issue happening, do that to see\n",
    "the full tensorflow logs during runtime.\n",
    "\"\"\"\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelName = \"SimpleDenseNet\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDirsAndClasses(root: str, file: str) -> Tuple[List[str], List[int]]:\n",
    "    imageDirs = []\n",
    "    classes = []\n",
    "    line = \"\"\n",
    "    with open(root + file, \"r\") as f:\n",
    "        for line in tqdm(f):\n",
    "            imageDir, clazz = line.split()\n",
    "            imageDirs.append(imageDir)\n",
    "            classes.append(int(clazz))\n",
    "    return imageDirs, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessImage(img: np.ndarray) -> tf.Tensor:\n",
    "    return img.astype(np.float16) / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeOneHot(value: int, size: int) -> np.ndarray:\n",
    "    onehot = np.zeros(size)\n",
    "    onehot[value] = 1\n",
    "    return onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balanceData(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    data = data.groupby(\"class\")\n",
    "    data = data.apply(lambda x: x.sample(data.size().min()).reset_index(drop=True))\n",
    "    return data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeDenseBlock(groupCount: int, inputs):\n",
    "    blockConcats = []\n",
    "    x = layers.BatchNormalization()(inputs)\n",
    "    x = layers.Conv2D(filters=64, kernel_size=(1, 1), activation=\"relu\", padding=\"same\")(x)\n",
    "    x = layers.Conv2D(filters=64, kernel_size=(3, 3), activation=\"relu\", padding=\"same\")(x)\n",
    "    blockConcats.append(x)\n",
    "    for count in range(groupCount):\n",
    "        x = layers.Concatenate()(blockConcats) if len(blockConcats) > 1 else x\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Conv2D(filters=64, kernel_size=(1, 1), activation=\"relu\", padding=\"same\")(x)\n",
    "        x = layers.Conv2D(filters=64, kernel_size=(3, 3), activation=\"relu\", padding=\"same\")(x)\n",
    "        blockConcats.append(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Conv2D(filters=64, kernel_size=(1, 1), activation=\"relu\", padding=\"same\")(x)\n",
    "    x = layers.AveragePooling2D(pool_size=(2, 2), strides=(2, 2))(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeModel(inputShape: Tuple[int], modelName=modelName) -> keras.Model:\n",
    "    inputs = keras.Input(shape=inputShape, name=\"Input\")\n",
    "    x = layers.Conv2D(filters=32, kernel_size=(7, 7), strides=(2, 2), activation=\"relu\")(inputs)\n",
    "    x = layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2))(x)\n",
    "    \n",
    "    x = makeDenseBlock(groupCount=6, inputs=x)\n",
    "    \n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    outputs = layers.Dense(units=2, activation=\"softmax\")(x)\n",
    "\n",
    "    return keras.Model(inputs=inputs, outputs=outputs, name=modelName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "144965it [00:00, 834819.30it/s]\n"
     ]
    }
   ],
   "source": [
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        monitor=\"accuracy\",\n",
    "        min_delta=0.01,\n",
    "        patience=3,\n",
    "        verbose=1\n",
    "    ),\n",
    "    tf.keras.callbacks.TensorBoard(\n",
    "        log_dir=f'logs/{modelName}',\n",
    "        write_graph=True,\n",
    "        write_images=True\n",
    "    )\n",
    "]\n",
    "\n",
    "root = os.getcwd() + \"\\\\Data\\\\CNR-EXT-150x150\"\n",
    "# train_imageDirs, train_classes = getDirsAndClasses(root, \"\\\\LABELS\\\\train.txt\")\n",
    "# test_imageDirs, test_classes = getDirsAndClasses(root, \"\\\\LABELS\\\\test.txt\")\n",
    "# val_imageDirs, val_classes = getDirsAndClasses(root, \"\\\\LABELS\\\\val.txt\")\n",
    "imageDirs, classes = getDirsAndClasses(root, \"\\\\LABELS\\\\all.txt\")\n",
    "\n",
    "classDict = {\n",
    "    0: \"free\",\n",
    "    1: \"busy\"\n",
    "}\n",
    "\n",
    "batchSize = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Acquisition and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "144965it [09:53, 244.27it/s]\n"
     ]
    }
   ],
   "source": [
    "data = pd.DataFrame([\n",
    "            {\n",
    "                \"image\": preprocessImage(cv2.imread(root + \"\\\\PATCHES\\\\\" + filename)),\n",
    "                \"class\": clazz,\n",
    "                \"weather\": filename[0]\n",
    "            }\n",
    "            for filename, clazz in tqdm(zip(imageDirs, classes))\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class  class\n",
       "0      0        65658\n",
       "1      1        79307\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby(\"class\")[\"class\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "weather  weather\n",
       "O        O          44243\n",
       "R        R          37544\n",
       "S        S          63178\n",
       "Name: weather, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby(\"weather\")[\"weather\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class  weather  class\n",
       "0      O        0        21067\n",
       "       R        0        18926\n",
       "       S        0        25665\n",
       "1      O        1        23176\n",
       "       R        1        18618\n",
       "       S        1        37513\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby([\"class\", \"weather\"])[\"class\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = list(data.groupby(\"class\").groups.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"onehot\"] = data[\"class\"].apply(\n",
    "    func=lambda x: makeOneHot(classes.index(x), len(classes))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data into train and test subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class  class\n",
       "0      0        52526\n",
       "1      1        63446\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = data.groupby(\"class\").sample(frac=0.8)\n",
    "train.groupby(\"class\")[\"class\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class  class\n",
       "0      0        13132\n",
       "1      1        15861\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = data.drop(train.index).reset_index(drop=True)\n",
    "test.groupby(\"class\")[\"class\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = tf.data.Dataset.from_tensor_slices(\n",
    "    (\n",
    "        np.array(train[\"image\"].values.tolist()),\n",
    "        np.array(train[\"onehot\"].values.tolist())\n",
    "    )\n",
    ").shuffle(\n",
    "    buffer_size=len(train),\n",
    "    reshuffle_each_iteration=True\n",
    ").batch(batchSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = tf.data.Dataset.from_tensor_slices(\n",
    "    (\n",
    "        np.array(test[\"image\"].values.tolist()),\n",
    "        np.array(test[\"onehot\"].values.tolist())\n",
    "    )\n",
    ").shuffle(\n",
    "    buffer_size=len(test),\n",
    "    reshuffle_each_iteration=True\n",
    ").batch(batchSize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = makeModel(inputShape=data.loc[0, \"image\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"SimpleDenseNet\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input (InputLayer)              [(None, 150, 150, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 72, 72, 32)   4736        Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 35, 35, 32)   0           conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 35, 35, 32)   128         max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 35, 35, 64)   2112        batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 35, 35, 64)   36928       conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 35, 35, 64)   256         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 35, 35, 64)   4160        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 35, 35, 64)   36928       conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 35, 35, 128)  0           conv2d_2[0][0]                   \n",
      "                                                                 conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 35, 35, 128)  512         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 35, 35, 64)   8256        batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 35, 35, 64)   36928       conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 35, 35, 192)  0           conv2d_2[0][0]                   \n",
      "                                                                 conv2d_4[0][0]                   \n",
      "                                                                 conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 35, 35, 192)  768         concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 35, 35, 64)   12352       batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 35, 35, 64)   36928       conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 35, 35, 256)  0           conv2d_2[0][0]                   \n",
      "                                                                 conv2d_4[0][0]                   \n",
      "                                                                 conv2d_6[0][0]                   \n",
      "                                                                 conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 35, 35, 256)  1024        concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 35, 35, 64)   16448       batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 35, 35, 64)   36928       conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 35, 35, 320)  0           conv2d_2[0][0]                   \n",
      "                                                                 conv2d_4[0][0]                   \n",
      "                                                                 conv2d_6[0][0]                   \n",
      "                                                                 conv2d_8[0][0]                   \n",
      "                                                                 conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 35, 35, 320)  1280        concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 35, 35, 64)   20544       batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 35, 35, 64)   36928       conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 35, 35, 384)  0           conv2d_2[0][0]                   \n",
      "                                                                 conv2d_4[0][0]                   \n",
      "                                                                 conv2d_6[0][0]                   \n",
      "                                                                 conv2d_8[0][0]                   \n",
      "                                                                 conv2d_10[0][0]                  \n",
      "                                                                 conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 35, 35, 384)  1536        concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 35, 35, 64)   24640       batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 35, 35, 64)   36928       conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 35, 35, 64)   256         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 35, 35, 64)   4160        batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 17, 17, 64)   0           conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 64)           0           average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 2)            130         global_average_pooling2d[0][0]   \n",
      "==================================================================================================\n",
      "Total params: 361,794\n",
      "Trainable params: 358,914\n",
      "Non-trainable params: 2,880\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "907/907 [==============================] - 153s 169ms/step - loss: 0.3503 - accuracy: 0.9626\n",
      "Epoch 2/100\n",
      "907/907 [==============================] - 159s 176ms/step - loss: 0.3401 - accuracy: 0.9724\n",
      "Epoch 3/100\n",
      "907/907 [==============================] - 164s 180ms/step - loss: 0.3340 - accuracy: 0.9787\n",
      "Epoch 4/100\n",
      "907/907 [==============================] - 168s 185ms/step - loss: 0.3314 - accuracy: 0.9815\n",
      "Epoch 5/100\n",
      "907/907 [==============================] - 172s 190ms/step - loss: 0.3307 - accuracy: 0.9820\n",
      "Epoch 6/100\n",
      "907/907 [==============================] - 176s 194ms/step - loss: 0.3287 - accuracy: 0.9841\n",
      "Epoch 00006: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1b8455a6f10>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    train,\n",
    "    epochs=100,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "227/227 [==============================] - 17s 75ms/step - loss: 0.3330 - accuracy: 0.9797\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8.3784743e-11, 1.0000000e+00],\n",
       "       [1.1414353e-14, 1.0000000e+00],\n",
       "       [2.3303061e-17, 1.0000000e+00],\n",
       "       ...,\n",
       "       [3.6013464e-10, 1.0000000e+00],\n",
       "       [4.4266863e-16, 1.0000000e+00],\n",
       "       [7.8299029e-09, 1.0000000e+00]], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.33301225304603577\n",
      "Test Accuracy: 0.9796847701072693\n"
     ]
    }
   ],
   "source": [
    "print(f'Test Loss: {loss}\\nTest Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(f'Models/{modelName}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "csc790",
   "language": "python",
   "name": "csc790"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
