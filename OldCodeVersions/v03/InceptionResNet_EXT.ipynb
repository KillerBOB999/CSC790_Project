{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Dropout, Activation, Flatten, Convolution2D, MaxPooling2D, BatchNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers\n",
    "from keras.models import Sequential\n",
    "from tensorflow.random import set_seed\n",
    "from typing import Tuple, List\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import keras\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seeding random state to 13 always, for reproducibility\n",
    "np.random.seed(13)\n",
    "set_seed(13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper Function: Return the paths to all jpg files found within a directory\n",
    "def getImageDirs(root: str = \"data\"):\n",
    "    imageDirs = []\n",
    "    for subDirectory, directory, files in os.walk(root):\n",
    "        for file in files:\n",
    "            if file[-4:] == \".jpg\":\n",
    "                path = os.path.join(subDirectory, file)         \n",
    "                imageDirs.append(path)\n",
    "    return(imageDirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper Function: Return the class weights given a list of classes\n",
    "def getClassWeightsFromLabels(labels: List[int]):# -> Dict[int]:\n",
    "    weights = sklearn.utils.class_weight.compute_class_weight(class_weight=\"balanced\", classes=np.unique(labels), y=labels)\n",
    "    return {0: weights[0], 1: weights[1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper Function: Return the img paths and classes in seperate lists given a txt file from the LABELS folder\n",
    "def getDirsAndClasses(root: str, file: str) -> Tuple[List[str], List[int]]:\n",
    "    imageDirs = []\n",
    "    classes = []\n",
    "    line = \"\"\n",
    "    with open(root + file, \"r\") as f:\n",
    "        for line in tqdm(f):\n",
    "            imageDir, clazz = line.split()\n",
    "            imageDirs.append(imageDir)\n",
    "            classes.append(int(clazz))\n",
    "    return imageDirs, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper Function: Create a Keras prebuilt model\n",
    "def makeModel(inputShape: Tuple[int], modelName:str ='') -> keras.Model:\n",
    "    \"\"\"\n",
    "    Source: https://www.tensorflow.org/guide/keras/functional#a_toy_resnet_model\n",
    "    \n",
    "    Note that I tend to prefer the super-explicit (if somewhat verbose) style. \n",
    "    This style is technically unnecessary, but it helps with readability.\n",
    "\n",
    "    Load model by inputing the name to modelName\n",
    "    Options are \"Simple_ResNet\", \"SimpleNet\", \"InceptionResNetV2\", \"MobileNetV2\", \"ResNet50V2\", \"DenseNet121\", \"DenseNet201\", and \"NASNetLarge\"\n",
    "    \"\"\"\n",
    "    input = keras.Input(shape=inputShape, name=\"Input\")\n",
    "    x=None\n",
    "    if modelName == \"Simple_ResNet\":\n",
    "\n",
    "        x = layers.Conv2D(filters=32, kernel_size=(3, 3), activation=\"relu\")(input)\n",
    "        x = layers.Conv2D(filters=64, kernel_size=(3, 3), activation=\"relu\")(x)\n",
    "        block_1_output = layers.MaxPooling2D(pool_size=(3, 3), strides=(3, 3))(x)\n",
    "\n",
    "        x = layers.Conv2D(filters=64, kernel_size=(3, 3), activation=\"relu\", padding=\"same\")(block_1_output)\n",
    "        x = layers.Conv2D(filters=64, kernel_size=(3, 3), activation=\"relu\", padding=\"same\")(x)\n",
    "        block_2_output = layers.add([x, block_1_output])\n",
    "\n",
    "        x = layers.Conv2D(filters=64, kernel_size=(3, 3), activation=\"relu\", padding=\"same\")(block_2_output)\n",
    "        x = layers.Conv2D(filters=64, kernel_size=(3, 3), activation=\"relu\", padding=\"same\")(x)\n",
    "        block_3_output = layers.add([x, block_2_output])\n",
    "\n",
    "        x = layers.Conv2D(filters=64, kernel_size=(3, 3), activation=\"relu\")(block_3_output)\n",
    "        x = layers.GlobalAveragePooling2D()(x)\n",
    "        x = layers.Dense(units=256, activation=\"relu\")(x)\n",
    "        x = layers.Dense(units=256, activation=\"relu\")(x)\n",
    "        x = layers.Dense(units=256, activation=\"relu\")(x)\n",
    "        x = layers.Dropout(0.5)(x)\n",
    "\n",
    "    elif modelName in [\"InceptionResNetV2\",\"MobileNetV2\",\"ResNet50V2\",\"DenseNet121\",\"DenseNet201\",\"NASNetLarge\"]:\n",
    "        \n",
    "        if modelName==\"InceptionResNetV2\":\n",
    "            baseModel = keras.applications.InceptionResNetV2(include_top=False, weights=\"imagenet\", input_shape=(150,150,3))(input)\n",
    "        elif modelName==\"MobileNetV2\":\n",
    "            baseModel = keras.applications.MobileNetV2(include_top=False, weights=\"imagenet\", input_shape=(150,150,3))(input)\n",
    "        elif modelName==\"ResNet50V2\":\n",
    "            baseModel = keras.applications.ResNet50V2(include_top=False, weights=\"imagenet\", input_shape=(150,150,3))(input)\n",
    "        elif modelName==\"DenseNet121\":\n",
    "            baseModel = keras.applications.DenseNet121(include_top=False, weights=\"imagenet\", input_shape=(150,150,3))(input)\n",
    "        elif modelName==\"DenseNet201\":\n",
    "            baseModel = keras.applications.DenseNet201(include_top=False, weights=\"imagenet\", input_shape=(150,150,3))(input)\n",
    "        elif modelName==\"NASNetLarge\":\n",
    "            x = tf.keras.layers.experimental.preprocessing.Resizing(height=331, width=331)(input)\n",
    "            baseModel = keras.applications.NASNetLarge(include_top=False, weights=\"imagenet\", input_shape=(331,331,3))(x)\n",
    "        else:\n",
    "            raise(\"Model Name Not In Recognized Keras Models\")\n",
    "        \n",
    "        baseModel.trainable = False\n",
    "        x = layers.Flatten()(baseModel)\n",
    "        x = layers.Dense(128, activation=\"relu\")(x)\n",
    "        x = layers.Dropout(0.3)(x)\n",
    "        x = layers.Dense(128, activation=\"relu\")(x)\n",
    "        x = layers.Dropout(0.3)(x)\n",
    "\n",
    "    elif modelName==\"SimpleNet\":\n",
    "        x = layers.AveragePooling2D(pool_size=(50, 50))(input)\n",
    "        x = layers.Flatten()(x)\n",
    "        x = layers.Dense(64, activation=\"relu\")(x)\n",
    "        x = layers.Dropout(0.3)(x)\n",
    "        x = layers.Dense(64, activation=\"relu\")(x)\n",
    "        x = layers.Dropout(0.3)(x)\n",
    "\n",
    "    if x != None:\n",
    "        output=layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "        return keras.Model(inputs=input, outputs=output, name=modelName)\n",
    "    else:\n",
    "        raise(\"Model Name Not Recognized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "94493it [00:00, 842960.84it/s]\n",
      "94493it [00:00, 1348752.83it/s]\n",
      "31825it [00:00, 847967.96it/s]\n",
      "31825it [00:00, 1445332.95it/s]\n"
     ]
    }
   ],
   "source": [
    "#Get the Train Dataset using split from the LABELS folder\n",
    "root = os.getcwd() + \"\\\\Data\\\\CNR-EXT-150x150\"\n",
    "imageDirs, classes = getDirsAndClasses(root, \"\\\\LABELS\\\\train.txt\")\n",
    "root = root + \"\\\\PATCHES\\\\\"\n",
    "train = pd.DataFrame([\n",
    "            {\n",
    "                \"image\": root + filename,\n",
    "                \"class\": \"free\" if clazz == 0 else \"busy\"\n",
    "            }\n",
    "            for filename, clazz in tqdm(zip(imageDirs, classes))\n",
    "    ])\n",
    "#Now Get Test\n",
    "root = os.getcwd() + \"\\\\Data\\\\CNR-EXT-150x150\"\n",
    "imageDirs, classes = getDirsAndClasses(root, \"\\\\LABELS\\\\test.txt\")\n",
    "root = root + \"\\\\PATCHES\\\\\"\n",
    "test = pd.DataFrame([\n",
    "            {\n",
    "                \"image\": root + filename,\n",
    "                \"class\": \"free\" if clazz == 0 else \"busy\"\n",
    "            }\n",
    "            for filename, clazz in tqdm(zip(imageDirs, classes))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\music\\anaconda3\\envs\\csc790\\lib\\site-packages\\keras_preprocessing\\image\\image_data_generator.py:356: UserWarning: This ImageDataGenerator specifies `samplewise_std_normalization`, which overrides setting of `samplewise_center`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 94493 non-validated image filenames belonging to 2 classes.\n",
      "Found 31825 non-validated image filenames belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\music\\anaconda3\\envs\\csc790\\lib\\site-packages\\keras_preprocessing\\image\\image_data_generator.py:356: UserWarning: This ImageDataGenerator specifies `samplewise_std_normalization`, which overrides setting of `samplewise_center`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n"
     ]
    }
   ],
   "source": [
    "#Declare data generators and preprocessing\n",
    "train_datagen = ImageDataGenerator(\n",
    "    #Augment data with random flips, normalize each sample's input\n",
    "    vertical_flip = True,\n",
    "    horizontal_flip = True,\n",
    "    rescale = 1.0 / 255.0,\n",
    "    samplewise_std_normalization = True\n",
    ")\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    directory = None, #none since the df has absolute paths\n",
    "    dataframe = train,\n",
    "    x_col = \"image\",\n",
    "    y_col = \"class\",\n",
    "    validate_filenames = False, #faster for huge datasets\n",
    "    target_size = (150, 150),\n",
    "    color_mode = \"rgb\",\n",
    "    batch_size = 128,\n",
    "    class_mode = \"binary\",\n",
    "    shuffle = True\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "    samplewise_std_normalization = True\n",
    ")\n",
    "test_generator = train_datagen.flow_from_dataframe(\n",
    "    directory = None,\n",
    "    dataframe = test,\n",
    "    x_col = \"image\",\n",
    "    y_col = \"class\",\n",
    "    validate_filenames = False,\n",
    "    target_size = (150, 150),\n",
    "    color_mode = \"rgb\",\n",
    "    batch_size = 128,\n",
    "    class_mode = \"binary\",\n",
    "    shuffle = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Declare Callbacks: stop training if accuracy doesn't rise 1% within 3 epochs\n",
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor = \"accuracy\",\n",
    "        min_delta = 0.01,\n",
    "        patience = 3,\n",
    "        verbose = 1\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0.992240003360215, 1: 1.0078823303539048}\n"
     ]
    }
   ],
   "source": [
    "#Extract Class Weights\n",
    "classes = list(train[\"class\"])\n",
    "weights_dict = getClassWeightsFromLabels(classes)\n",
    "print(weights_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_resnet_v2/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "219062272/219055592 [==============================] - 365s 2us/step\n"
     ]
    }
   ],
   "source": [
    "#Build Model\n",
    "Model = makeModel((150, 150, 3), \"InceptionResNetV2\")\n",
    "opt = tf.optimizers.Adam()\n",
    "Model.compile(\n",
    "    optimizer = opt,\n",
    "    loss = keras.losses.BinaryCrossentropy(from_logits = True),\n",
    "    metrics = [\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"InceptionResNetV2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Input (InputLayer)           [(None, 150, 150, 3)]     0         \n",
      "_________________________________________________________________\n",
      "inception_resnet_v2 (Functio (None, 3, 3, 1536)        54336736  \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 13824)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               1769600   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 56,122,977\n",
      "Trainable params: 56,062,433\n",
      "Non-trainable params: 60,544\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "Model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "  2/739 [..............................] - ETA: 3:07 - loss: 0.6435 - accuracy: 0.4531WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1892s vs `on_train_batch_end` time: 0.3188s). Check your callbacks.\n",
      "739/739 [==============================] - 376s 509ms/step - loss: 0.5274 - accuracy: 0.9481\n",
      "Epoch 2/100\n",
      "739/739 [==============================] - 372s 504ms/step - loss: 0.5260 - accuracy: 0.9503\n",
      "Epoch 3/100\n",
      "739/739 [==============================] - 373s 504ms/step - loss: 0.5272 - accuracy: 0.9493\n",
      "Epoch 4/100\n",
      "739/739 [==============================] - 373s 505ms/step - loss: 0.5335 - accuracy: 0.9366\n",
      "Epoch 00004: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1f433de6730>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit data\n",
    "Model.fit(\n",
    "    train_generator,\n",
    "    callbacks = callbacks,\n",
    "    epochs = 100,\n",
    "    class_weight = weights_dict,\n",
    "    max_queue_size = 1000,\n",
    "    workers = os.cpu_count()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "249/249 [==============================] - 51s 205ms/step - loss: 0.5706 - accuracy: 0.9275\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5705567598342896, 0.9275412559509277]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test accuracy\n",
    "Model.evaluate(\n",
    "    test_generator,\n",
    "    max_queue_size = 1000,\n",
    "    workers = os.cpu_count()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\music\\anaconda3\\envs\\csc790\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From C:\\Users\\music\\anaconda3\\envs\\csc790\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: Models/InceptionResnet\\assets\n"
     ]
    }
   ],
   "source": [
    "#Save the model\n",
    "Model.save(\"Models/InceptionResnet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "csc790",
   "language": "python",
   "name": "csc790"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
