{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Dropout, Activation, Flatten, Convolution2D, MaxPooling2D, BatchNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers\n",
    "from keras.models import Sequential\n",
    "from typing import Tuple, List\n",
    "import tensorflow as tf\n",
    "from tensorflow.random import set_seed\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import keras\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seeding random state to 13 always, for reproducibility\n",
    "np.random.seed(13)\n",
    "set_seed(13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper Function: Return the paths to all jpg files found within a directory\n",
    "def getImageDirs(root: str = \"data\"):\n",
    "    imageDirs = []\n",
    "    for subDirectory, directory, files in os.walk(root):\n",
    "        for file in files:\n",
    "            if file[-4:] == \".jpg\":\n",
    "                path = os.path.join(subDirectory, file)         \n",
    "                imageDirs.append(path)\n",
    "    return(imageDirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper Function: Return the class weights given a list of classes\n",
    "def getClassWeightsFromLabels(labels: List[int]):# -> Dict[int]:\n",
    "    weights = sklearn.utils.class_weight.compute_class_weight(class_weight=\"balanced\", classes=np.unique(labels), y=labels)\n",
    "    return {0: weights[0], 1: weights[1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper Function: Return the img paths and classes in seperate lists given a txt file from the LABELS folder\n",
    "def getDirsAndClasses(root: str, file: str) -> Tuple[List[str], List[int]]:\n",
    "    imageDirs = []\n",
    "    classes = []\n",
    "    line = \"\"\n",
    "    with open(root + file, \"r\") as f:\n",
    "        for line in tqdm(f):\n",
    "            imageDir, clazz = line.split()\n",
    "            imageDirs.append(imageDir)\n",
    "            classes.append(int(clazz))\n",
    "    return imageDirs, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper Function: Create a Keras prebuilt model\n",
    "def makeDenseBlock(groupCount: int, inputs):\n",
    "    blockConcats = []\n",
    "    x = layers.BatchNormalization()(inputs)\n",
    "    x = layers.Conv2D(filters=64, kernel_size=(1, 1), activation=\"relu\", padding=\"same\")(x)\n",
    "    x = layers.Conv2D(filters=64, kernel_size=(3, 3), activation=\"relu\", padding=\"same\")(x)\n",
    "    blockConcats.append(x)\n",
    "    for count in range(groupCount):\n",
    "        x = layers.Concatenate()(blockConcats) if len(blockConcats) > 1 else x\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Conv2D(filters=64, kernel_size=(1, 1), activation=\"relu\", padding=\"same\")(x)\n",
    "        x = layers.Conv2D(filters=64, kernel_size=(3, 3), activation=\"relu\", padding=\"same\")(x)\n",
    "        blockConcats.append(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Conv2D(filters=64, kernel_size=(1, 1), activation=\"relu\", padding=\"same\")(x)\n",
    "    x = layers.AveragePooling2D(pool_size=(2, 2), strides=(2, 2))(x)\n",
    "    return x\n",
    "def makeModel(inputShape: Tuple[int]) -> keras.Model:\n",
    "    inputs = keras.Input(shape=inputShape, name=\"Input\")\n",
    "    x = layers.Conv2D(filters=32, kernel_size=(7, 7), strides=(2, 2), activation=\"relu\")(inputs)\n",
    "    x = layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2))(x)\n",
    "    \n",
    "    x = makeDenseBlock(groupCount=6, inputs=x)\n",
    "    \n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    outputs = layers.Dense(units=1, activation=\"sigmoid\")(x)\n",
    "\n",
    "    return keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "94493it [00:00, 846737.39it/s]\n",
      "94493it [00:00, 646653.06it/s]\n",
      "31825it [00:00, 859411.05it/s]\n",
      "31825it [00:00, 1353104.15it/s]\n"
     ]
    }
   ],
   "source": [
    "#Get the Train Dataset using split from the LABELS folder\n",
    "root = os.getcwd() + \"\\\\Data\\\\CNR-EXT-150x150\"\n",
    "imageDirs, classes = getDirsAndClasses(root, \"\\\\LABELS\\\\train.txt\")\n",
    "root = root + \"\\\\PATCHES\\\\\"\n",
    "train = pd.DataFrame([\n",
    "            {\n",
    "                \"image\": root + filename,\n",
    "                \"class\": \"free\" if clazz == 0 else \"busy\"\n",
    "            }\n",
    "            for filename, clazz in tqdm(zip(imageDirs, classes))\n",
    "    ])\n",
    "#Now Get Test\n",
    "root = os.getcwd() + \"\\\\Data\\\\CNR-EXT-150x150\"\n",
    "imageDirs, classes = getDirsAndClasses(root, \"\\\\LABELS\\\\test.txt\")\n",
    "root = root + \"\\\\PATCHES\\\\\"\n",
    "test = pd.DataFrame([\n",
    "            {\n",
    "                \"image\": root + filename,\n",
    "                \"class\": \"free\" if clazz == 0 else \"busy\"\n",
    "            }\n",
    "            for filename, clazz in tqdm(zip(imageDirs, classes))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\music\\anaconda3\\envs\\csc790\\lib\\site-packages\\keras_preprocessing\\image\\image_data_generator.py:356: UserWarning: This ImageDataGenerator specifies `samplewise_std_normalization`, which overrides setting of `samplewise_center`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 94493 non-validated image filenames belonging to 2 classes.\n",
      "Found 31825 non-validated image filenames belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\music\\anaconda3\\envs\\csc790\\lib\\site-packages\\keras_preprocessing\\image\\image_data_generator.py:356: UserWarning: This ImageDataGenerator specifies `samplewise_std_normalization`, which overrides setting of `samplewise_center`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n"
     ]
    }
   ],
   "source": [
    "#Declare data generators and preprocessing\n",
    "train_datagen = ImageDataGenerator(\n",
    "    #Augment data with random flips, normalize each sample's input\n",
    "    vertical_flip = True,\n",
    "    horizontal_flip = True,\n",
    "    rescale = 1.0 / 255.0,\n",
    "    samplewise_std_normalization = True\n",
    ")\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    directory = None, #none since the df has absolute paths\n",
    "    dataframe = train,\n",
    "    x_col = \"image\",\n",
    "    y_col = \"class\",\n",
    "    validate_filenames = False, #faster for huge datasets\n",
    "    target_size = (150, 150),\n",
    "    color_mode = \"rgb\",\n",
    "    batch_size = 128,\n",
    "    class_mode = \"binary\",\n",
    "    shuffle = True\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "    samplewise_std_normalization = True\n",
    ")\n",
    "test_generator = train_datagen.flow_from_dataframe(\n",
    "    directory = None,\n",
    "    dataframe = test,\n",
    "    x_col = \"image\",\n",
    "    y_col = \"class\",\n",
    "    validate_filenames = False,\n",
    "    target_size = (150, 150),\n",
    "    color_mode = \"rgb\",\n",
    "    batch_size = 128,\n",
    "    class_mode = \"binary\",\n",
    "    shuffle = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Declare Callbacks: stop training if accuracy doesn't rise 1% within 3 epochs\n",
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor = \"accuracy\",\n",
    "        min_delta = 0.01,\n",
    "        patience = 3,\n",
    "        verbose = 1\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0.992240003360215, 1: 1.0078823303539048}\n"
     ]
    }
   ],
   "source": [
    "#Extract Class Weights\n",
    "classes = list(train[\"class\"])\n",
    "weights_dict = getClassWeightsFromLabels(classes)\n",
    "print(weights_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build Model\n",
    "Model = makeModel((150, 150, 3))\n",
    "opt = tf.optimizers.Adam()\n",
    "Model.compile(\n",
    "    optimizer = opt,\n",
    "    loss = keras.losses.BinaryCrossentropy(from_logits = True),\n",
    "    metrics = [\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input (InputLayer)              [(None, 150, 150, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 72, 72, 32)   4736        Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 35, 35, 32)   0           conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 35, 35, 32)   128         max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 35, 35, 64)   2112        batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 35, 35, 64)   36928       conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 35, 35, 64)   256         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 35, 35, 64)   4160        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 35, 35, 64)   36928       conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 35, 35, 128)  0           conv2d_2[0][0]                   \n",
      "                                                                 conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 35, 35, 128)  512         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 35, 35, 64)   8256        batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 35, 35, 64)   36928       conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 35, 35, 192)  0           conv2d_2[0][0]                   \n",
      "                                                                 conv2d_4[0][0]                   \n",
      "                                                                 conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 35, 35, 192)  768         concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 35, 35, 64)   12352       batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 35, 35, 64)   36928       conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 35, 35, 256)  0           conv2d_2[0][0]                   \n",
      "                                                                 conv2d_4[0][0]                   \n",
      "                                                                 conv2d_6[0][0]                   \n",
      "                                                                 conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 35, 35, 256)  1024        concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 35, 35, 64)   16448       batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 35, 35, 64)   36928       conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 35, 35, 320)  0           conv2d_2[0][0]                   \n",
      "                                                                 conv2d_4[0][0]                   \n",
      "                                                                 conv2d_6[0][0]                   \n",
      "                                                                 conv2d_8[0][0]                   \n",
      "                                                                 conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 35, 35, 320)  1280        concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 35, 35, 64)   20544       batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 35, 35, 64)   36928       conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 35, 35, 384)  0           conv2d_2[0][0]                   \n",
      "                                                                 conv2d_4[0][0]                   \n",
      "                                                                 conv2d_6[0][0]                   \n",
      "                                                                 conv2d_8[0][0]                   \n",
      "                                                                 conv2d_10[0][0]                  \n",
      "                                                                 conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 35, 35, 384)  1536        concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 35, 35, 64)   24640       batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 35, 35, 64)   36928       conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 35, 35, 64)   256         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 35, 35, 64)   4160        batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 17, 17, 64)   0           conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 64)           0           average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            65          global_average_pooling2d[0][0]   \n",
      "==================================================================================================\n",
      "Total params: 361,729\n",
      "Trainable params: 358,849\n",
      "Non-trainable params: 2,880\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "Model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "  2/739 [..............................] - ETA: 48s - loss: 0.6802 - accuracy: 0.5820WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0500s vs `on_train_batch_end` time: 0.0786s). Check your callbacks.\n",
      "739/739 [==============================] - 92s 125ms/step - loss: 0.5281 - accuracy: 0.9471\n",
      "Epoch 2/100\n",
      "739/739 [==============================] - 92s 125ms/step - loss: 0.5203 - accuracy: 0.9628\n",
      "Epoch 3/100\n",
      "739/739 [==============================] - 92s 125ms/step - loss: 0.5177 - accuracy: 0.9684\n",
      "Epoch 4/100\n",
      "739/739 [==============================] - 92s 124ms/step - loss: 0.5170 - accuracy: 0.9698\n",
      "Epoch 5/100\n",
      "739/739 [==============================] - 92s 125ms/step - loss: 0.5157 - accuracy: 0.9733\n",
      "Epoch 6/100\n",
      "739/739 [==============================] - 92s 125ms/step - loss: 0.5149 - accuracy: 0.9744\n",
      "Epoch 7/100\n",
      "739/739 [==============================] - 92s 124ms/step - loss: 0.5146 - accuracy: 0.9750\n",
      "Epoch 8/100\n",
      "739/739 [==============================] - 92s 125ms/step - loss: 0.5139 - accuracy: 0.9768\n",
      "Epoch 00008: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x274dc6d38b0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit data\n",
    "Model.fit(\n",
    "    train_generator,\n",
    "    callbacks = callbacks,\n",
    "    epochs = 100,\n",
    "    class_weight = weights_dict,\n",
    "    max_queue_size = 1000,\n",
    "    workers = os.cpu_count()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "249/249 [==============================] - 28s 114ms/step - loss: 0.5462 - accuracy: 0.9625\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5462340116500854, 0.9624509215354919]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test accuracy\n",
    "Model.evaluate(\n",
    "    test_generator,\n",
    "    max_queue_size = 1000,\n",
    "    workers = os.cpu_count()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\music\\anaconda3\\envs\\csc790\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From C:\\Users\\music\\anaconda3\\envs\\csc790\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: Models/simpleDenseNet\\assets\n"
     ]
    }
   ],
   "source": [
    "#Save the model\n",
    "Model.save(\"Models/simpleDenseNet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "csc790",
   "language": "python",
   "name": "csc790"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
