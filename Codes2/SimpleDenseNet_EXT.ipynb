{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "fb3e69b1849fbe3db38258675c90eca9b4601c3e4a5f4e71200d2f3e80de7811"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Dropout, Activation, Flatten, Convolution2D, MaxPooling2D, BatchNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers\n",
    "from keras.models import Sequential\n",
    "from typing import Tuple, List\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import keras\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seeding random state to 13 always, for reproducibility\n",
    "np.random.seed(13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper Function: Return the paths to all jpg files found within a directory\n",
    "def getImageDirs(root: str = \"data\"):\n",
    "    imageDirs = []\n",
    "    for subDirectory, directory, files in os.walk(root):\n",
    "        for file in files:\n",
    "            if file[-4:] == \".jpg\":\n",
    "                path = os.path.join(subDirectory, file)         \n",
    "                imageDirs.append(path)\n",
    "    return(imageDirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper Function: Return the class weights given a list of classes\n",
    "def getClassWeightsFromLabels(labels: List[int]):# -> Dict[int]:\n",
    "    weights = sklearn.utils.class_weight.compute_class_weight(class_weight=\"balanced\", classes=np.unique(labels), y=labels)\n",
    "    return {0: weights[0], 1: weights[1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper Function: Return the img paths and classes in seperate lists given a txt file from the LABELS folder\n",
    "def getDirsAndClasses(root: str, file: str) -> Tuple[List[str], List[int]]:\n",
    "    imageDirs = []\n",
    "    classes = []\n",
    "    line = \"\"\n",
    "    with open(root + file, \"r\") as f:\n",
    "        for line in tqdm(f):\n",
    "            imageDir, clazz = line.split()\n",
    "            imageDirs.append(imageDir)\n",
    "            classes.append(int(clazz))\n",
    "    return imageDirs, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper Function: Create a Keras prebuilt model\n",
    "def makeDenseBlock(groupCount: int, inputs):\n",
    "    blockConcats = []\n",
    "    x = layers.BatchNormalization()(inputs)\n",
    "    x = layers.Conv2D(filters=64, kernel_size=(1, 1), activation=\"relu\", padding=\"same\")(x)\n",
    "    x = layers.Conv2D(filters=64, kernel_size=(3, 3), activation=\"relu\", padding=\"same\")(x)\n",
    "    blockConcats.append(x)\n",
    "    for count in range(groupCount):\n",
    "        x = layers.Concatenate()(blockConcats) if len(blockConcats) > 1 else x\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Conv2D(filters=64, kernel_size=(1, 1), activation=\"relu\", padding=\"same\")(x)\n",
    "        x = layers.Conv2D(filters=64, kernel_size=(3, 3), activation=\"relu\", padding=\"same\")(x)\n",
    "        blockConcats.append(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Conv2D(filters=64, kernel_size=(1, 1), activation=\"relu\", padding=\"same\")(x)\n",
    "    x = layers.AveragePooling2D(pool_size=(2, 2), strides=(2, 2))(x)\n",
    "    return x\n",
    "def makeModel(inputShape: Tuple[int]) -> keras.Model:\n",
    "    inputs = keras.Input(shape=inputShape, name=\"Input\")\n",
    "    x = layers.Conv2D(filters=32, kernel_size=(7, 7), strides=(2, 2), activation=\"relu\")(inputs)\n",
    "    x = layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2))(x)\n",
    "    \n",
    "    x = makeDenseBlock(groupCount=6, inputs=x)\n",
    "    \n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    outputs = layers.Dense(units=1, activation=\"sigmoid\")(x)\n",
    "\n",
    "    return keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the Train Dataset using split from the LABELS folder\n",
    "root = os.getcwd() + \"\\\\Data\\\\CNR-EXT-150x150\"\n",
    "imageDirs, classes = getDirsAndClasses(root, \"\\\\LABELS\\\\train.txt\")\n",
    "root = root + \"\\\\PATCHES\\\\\"\n",
    "train = pd.DataFrame([\n",
    "            {\n",
    "                \"image\": root + filename,\n",
    "                \"class\": \"free\" if clazz == 0 else \"busy\"\n",
    "            }\n",
    "            for filename, clazz in tqdm(zip(imageDirs, classes))\n",
    "    ])\n",
    "#Now Get Test\n",
    "root = os.getcwd() + \"\\\\Data\\\\CNR-EXT-150x150\"\n",
    "imageDirs, classes = getDirsAndClasses(root, \"\\\\LABELS\\\\test.txt\")\n",
    "root = root + \"\\\\PATCHES\\\\\"\n",
    "test = pd.DataFrame([\n",
    "            {\n",
    "                \"image\": root + filename,\n",
    "                \"class\": \"free\" if clazz == 0 else \"busy\"\n",
    "            }\n",
    "            for filename, clazz in tqdm(zip(imageDirs, classes))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Declare data generators and preprocessing\n",
    "train_datagen = ImageDataGenerator(\n",
    "    #Augment data with random flips, normalize each sample's input\n",
    "    vertical_flip = True,\n",
    "    horizontal_flip = True,\n",
    "    rescale = 1.0 / 255.0,\n",
    "    samplewise_std_normalization = True\n",
    ")\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    directory = None, #none since the df has absolute paths\n",
    "    dataframe = train,\n",
    "    x_col = \"image\",\n",
    "    y_col = \"class\",\n",
    "    validate_filenames = False, #faster for huge datasets\n",
    "    target_size = (150, 150),\n",
    "    color_mode = \"rgb\",\n",
    "    batch_size = 128,\n",
    "    class_mode = \"binary\",\n",
    "    shuffle = True\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "    samplewise_std_normalization = True\n",
    ")\n",
    "test_generator = train_datagen.flow_from_dataframe(\n",
    "    directory = None,\n",
    "    dataframe = test,\n",
    "    x_col = \"image\",\n",
    "    y_col = \"class\",\n",
    "    validate_filenames = False,\n",
    "    target_size = (150, 150),\n",
    "    color_mode = \"rgb\",\n",
    "    batch_size = 128,\n",
    "    class_mode = \"binary\",\n",
    "    shuffle = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Declare Callbacks: stop training if accuracy doesn't rise 1% within 3 epochs\n",
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor = \"accuracy\",\n",
    "        min_delta = 0.01,\n",
    "        patience = 3,\n",
    "        verbose = 1\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract Class Weights\n",
    "classes = list(train[\"class\"])\n",
    "weights_dict = getClassWeightsFromLabels(classes)\n",
    "print(weights_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build Model\n",
    "Model = makeModel((150, 150, 3))\n",
    "opt = tf.optimizers.Adam()\n",
    "Model.compile(\n",
    "    optimizer = opt,\n",
    "    loss = keras.losses.BinaryCrossentropy(from_logits = True),\n",
    "    metrics = [\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit data\n",
    "Model.fit(train_generator, callbacks = callbacks, epochs = 100, class_weight = weights_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test accuracy\n",
    "Model.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the model\n",
    "Model.save(\"Models/simpleDenseNet\")"
   ]
  }
 ]
}